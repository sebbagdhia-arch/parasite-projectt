import streamlit as st
import tensorflow as tf
from PIL import Image, ImageOps
import numpy as np
import os

# --- 1. Ø­Ù„ Ù…Ø´ÙƒÙ„Ø© Ø§Ù„ØªÙˆØ§ÙÙ‚ Ù…Ø¹ ØªØ­Ø¯ÙŠØ«Ø§Øª Keras Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© ---
import keras
# Ù†Ù‚ÙˆÙ… Ø¨ØªØ¹Ø¯ÙŠÙ„ ÙˆØ¸ÙŠÙØ© Ø§Ù„Ø·Ø¨Ù‚Ø© Ø§Ù„Ù…Ø¹Ù‚Ø¯Ø© Ù„ØªØ¹Ù…Ù„ Ù…Ø¹ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©
if hasattr(keras.layers, 'DepthwiseConv2D'):
    orig_init = keras.layers.DepthwiseConv2D.__init__
    def new_init(self, *args, **kwargs):
        kwargs.pop('groups', None) # Ø­Ø°Ù Ø§Ù„Ù…Ø¹Ø§Ù…Ù„ Ø§Ù„Ù…Ø³Ø¨Ø¨ Ù„Ù„Ù…Ø´Ø§ÙƒÙ„
        orig_init(self, *args, **kwargs)
    keras.layers.DepthwiseConv2D.__init__ = new_init

# --- 2. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© ---
st.set_page_config(page_title="ÙƒØ§Ø´Ù Ø§Ù„Ø·ÙÙŠÙ„ÙŠØ§Øª", layout="centered")
st.title("ğŸ”¬ Ù†Ø¸Ø§Ù… Ø§Ù„ØªÙ…ÙŠÙŠØ² Ø§Ù„Ø¢Ù„ÙŠ Ù„Ù„Ø·ÙÙŠÙ„ÙŠØ§Øª")
st.write("---")

# --- 3. Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…Ù„ÙØ§Øª ÙˆØ§Ù„ØªØ­Ù‚Ù‚ Ù…Ù†Ù‡Ø§ ---
def find_files():
    m_file = next((f for f in os.listdir() if f.endswith(".h5")), None)
    l_file = next((f for f in os.listdir() if f.endswith(".txt") and f != "requirements.txt"), None)
    return m_file, l_file

model_path, label_path = find_files()

# ÙØ­Øµ Ø³Ù„Ø§Ù…Ø© Ø§Ù„Ù…Ù„Ù Ù‚Ø¨Ù„ Ø§Ù„ØªØ­Ù…ÙŠÙ„
if model_path:
    file_size_mb = os.path.getsize(model_path) / (1024 * 1024)
    if file_size_mb < 1:
        st.error(f"âš ï¸ Ù…Ù„Ù Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØªØ§Ù„Ù Ø£Ùˆ ØºÙŠØ± Ù…ÙƒØªÙ…Ù„! Ø§Ù„Ø­Ø¬Ù… Ø§Ù„Ø­Ø§Ù„ÙŠ: {file_size_mb:.2f} MB (ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ø£ÙƒØ¨Ø± Ù…Ù† 2 MB).")
        st.stop()

@st.cache_resource
def load_my_model(m_path, l_path):
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø¯ÙˆÙ† ØªØ±Ø¬Ù…Ø© Ù„ØªØ¬Ù†Ø¨ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
    model = tf.keras.models.load_model(m_path, compile=False)
    with open(l_path, "r", encoding="utf-8") as f:
        class_names = [line.strip() for line in f.readlines()]
    return model, class_names

if model_path and label_path:
    try:
        model, class_names = load_my_model(model_path, label_path)
        
        # ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§
        source = st.camera_input("Ø§Ù„ØªÙ‚Ø· ØµÙˆØ±Ø© Ù„Ù„Ø¹ÙŠÙ†Ø© Ø§Ù„Ù…Ø¬Ù‡Ø±ÙŠØ©")
        
        if source:
            # Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ±Ø©
            image = Image.open(source).convert("RGB")
            st.image(image, caption="ØªÙ… Ø§Ù„ØªÙ‚Ø§Ø· Ø§Ù„ØµÙˆØ±Ø©", use_container_width=True)
            
            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø©
            size = (224, 224)
            image = ImageOps.fit(image, size, Image.Resampling.LANCZOS)
            img_array = np.asarray(image).astype(np.float32) / 127.5 - 1
            data = np.expand_dims(img_array, axis=0)
            
            # --- 4. Ø§Ù„ØªÙˆÙ‚Ø¹ (Ø§Ù„Ø­Ù„ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ù„Ù…Ø´ÙƒÙ„Ø© Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„) ---
            # Ù†Ø³ØªØ®Ø¯Ù… model(...) Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† model.predict Ù„ØªØ¬Ù†Ø¨ ØªÙƒØ±Ø§Ø± Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„
            prediction_tensor = model(tf.constant(data), training=False)
            prediction = prediction_tensor.numpy()
            
            index = np.argmax(prediction)
            label_text = class_names[index]
            
            # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ (Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ø±Ù‚Ø§Ù… ÙÙŠ Ø§Ù„Ø¨Ø¯Ø§ÙŠØ© Ø¥Ù† ÙˆØ¬Ø¯Øª)
            if " " in label_text:
                label_text = label_text.split(" ", 1)[1]

            confidence = prediction[0][index]
            
            st.success(f"Ø§Ù„Ù†ØªÙŠØ¬Ø©: **{label_text}**")
            st.metric(label="Ø¯Ø±Ø¬Ø© Ø§Ù„Ø«Ù‚Ø© (Ø§Ù„Ø¯Ù‚Ø©)", value=f"{confidence*100:.2f}%")
            
    except Exception as e:
        st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹: {e}")
        st.info("Ø¬Ø±Ø¨ Ø¹Ù…Ù„ Reboot Ù„Ù„ØªØ·Ø¨ÙŠÙ‚ Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©.")
else:
    st.warning("âš ï¸ ÙŠØ±Ø¬Ù‰ Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø±ÙØ¹ Ù…Ù„ÙØ§Øª .h5 Ùˆ .txt Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­.")
