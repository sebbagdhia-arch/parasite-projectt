import streamlit as st
import tensorflow as tf
from PIL import Image, ImageOps
import numpy as np
import os

# -----------------------------------------------------------
# 1. ØªØµØ­ÙŠØ­ Ù…Ø´ÙƒÙ„Ø© DepthwiseConv2D (Ù„Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©)
# -----------------------------------------------------------
import keras
if hasattr(keras.layers, 'DepthwiseConv2D'):
    orig_init = keras.layers.DepthwiseConv2D.__init__
    def new_init(self, *args, **kwargs):
        kwargs.pop('groups', None)
        orig_init(self, *args, **kwargs)
    keras.layers.DepthwiseConv2D.__init__ = new_init

# -----------------------------------------------------------
# 2. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø©
# -----------------------------------------------------------
st.set_page_config(page_title="ÙƒØ§Ø´Ù Ø§Ù„Ø·ÙÙŠÙ„ÙŠØ§Øª", layout="centered")
st.title("ğŸ”¬ Ù†Ø¸Ø§Ù… Ø§Ù„ØªÙ…ÙŠÙŠØ² Ø§Ù„Ø¢Ù„ÙŠ Ù„Ù„Ø·ÙÙŠÙ„ÙŠØ§Øª")

# -----------------------------------------------------------
# 3. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
# -----------------------------------------------------------
def find_files():
    m_file = next((f for f in os.listdir() if f.endswith(".h5")), None)
    l_file = next((f for f in os.listdir() if f.endswith(".txt") and f != "requirements.txt"), None)
    return m_file, l_file

model_path, label_path = find_files()

@st.cache_resource
def load_my_model(m_path, l_path):
    model = tf.keras.models.load_model(m_path, compile=False)
    with open(l_path, "r", encoding="utf-8") as f:
        class_names = [line.strip() for line in f.readlines()]
    return model, class_names

if model_path and label_path:
    # ÙØ­Øµ Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù
    if os.path.getsize(model_path) / (1024 * 1024) < 1:
        st.error("âš ï¸ Ù…Ù„Ù Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙŠØ¨Ø¯Ùˆ ØªØ§Ù„ÙØ§Ù‹ (Ø£Ù‚Ù„ Ù…Ù† 1 Ù…ÙŠØ¬Ø§Ø¨Ø§ÙŠØª). Ø£Ø¹Ø¯ Ø±ÙØ¹Ù‡.")
        st.stop()

    try:
        model, class_names = load_my_model(model_path, label_path)
        
        source = st.camera_input("Ø§Ù„ØªÙ‚Ø· ØµÙˆØ±Ø© Ù„Ù„Ø¹ÙŠÙ†Ø©")
        
        if source:
            image = Image.open(source).convert("RGB")
            st.image(image, caption="ØªÙ… Ø§Ù„Ø§Ù„ØªÙ‚Ø§Ø·", use_container_width=True)
            
            # ØªØ¬Ù‡ÙŠØ² Ø§Ù„ØµÙˆØ±Ø©
            size = (224, 224)
            image = ImageOps.fit(image, size, Image.Resampling.LANCZOS)
            img_array = np.asarray(image).astype(np.float32) / 127.5 - 1
            data = np.expand_dims(img_array, axis=0)
            
            # -----------------------------------------------------------
            # 4. Ø§Ù„ØªÙˆÙ‚Ø¹ Ø§Ù„Ø°ÙƒÙŠ (Ø§Ù„Ø­Ù„ Ù„Ù„Ù…Ø´ÙƒÙ„Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©)
            # -----------------------------------------------------------
            try:
                # Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰: Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø¹Ø§Ø¯ÙŠØ©
                prediction = model.predict(data)
            except Exception:
                # Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ©: ÙƒØ³Ø± Ø§Ù„ØºÙ„Ø§Ù ÙˆØ§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø·Ø¨Ù‚Ø© Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØ© Ù…Ø¨Ø§Ø´Ø±Ø©
                # Ù‡Ø°Ø§ ÙŠØªØ®Ø·Ù‰ Ø®Ø·Ø£ "2 input tensors"
                prediction = model.layers[0](tf.constant(data), training=False)
                prediction = prediction.numpy()
            
            # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
            index = np.argmax(prediction)
            label_text = class_names[index]
            confidence = prediction[0][index]
            
            # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ
            if " " in label_text:
                label_text = label_text.split(" ", 1)[1]
            
            st.success(f"Ø§Ù„Ù†ØªÙŠØ¬Ø©: **{label_text}**")
            st.metric("Ø¯Ø±Ø¬Ø© Ø§Ù„Ø«Ù‚Ø©", f"{confidence*100:.2f}%")
            
    except Exception as e:
        st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£: {e}")
        
else:
    st.warning("ÙŠØ±Ø¬Ù‰ Ø±ÙØ¹ Ù…Ù„ÙØ§Øª .h5 Ùˆ .txt")
