import streamlit as st
import tensorflow as tf
from PIL import Image, ImageOps
import numpy as np
import os
import keras

# 1. Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ø·Ø¨Ù‚Ø§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© (DepthwiseConv2D)
class PatchedDepthwiseConv2D(tf.keras.layers.DepthwiseConv2D):
    def __init__(self, *args, **kwargs):
        kwargs.pop('groups', None)
        super().__init__(*args, **kwargs)

st.set_page_config(page_title="ÙƒØ§Ø´Ù Ø§Ù„Ø·ÙÙŠÙ„ÙŠØ§Øª Ø§Ù„Ù…Ø¬Ù‡Ø±ÙŠ", layout="centered")
st.title("ğŸ”¬ Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ´Ø®ÙŠØµ Ø§Ù„Ø¢Ù„ÙŠ (Ø§Ù„Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ù…ØµØ­Ø­)")

def find_files():
    m = next((f for f in os.listdir() if f.endswith(".h5")), None)
    l = next((f for f in os.listdir() if f.endswith(".txt") and "req" not in f), None)
    return m, l

model_path, label_path = find_files()

@st.cache_resource
def load_and_fix_model(m_path, l_path):
    custom_objects = {'DepthwiseConv2D': PatchedDepthwiseConv2D}
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ
    base_model = tf.keras.models.load_model(m_path, custom_objects=custom_objects, compile=False)
    
    # --- Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø¬Ø±Ø§Ø­ÙŠØ© ---
    # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ø¨Ø§Ø±Ø© Ø¹Ù† "ØºÙ„Ø§Ù" (Sequential)ØŒ Ø³Ù†Ø®ØªØ±Ù‚Ù‡ Ù„Ù„ÙˆØµÙˆÙ„ Ù„Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠ
    if hasattr(base_model, 'layers'):
        for layer in base_model.layers:
            if "functional" in layer.name.lower() or isinstance(layer, tf.keras.Model):
                final_model = layer
                break
        else:
            final_model = base_model
    else:
        final_model = base_model
        
    with open(l_path, "r", encoding="utf-8") as f:
        labels = [line.strip() for line in f.readlines()]
    return final_model, labels

if model_path and label_path:
    try:
        model, class_names = load_and_fix_model(model_path, label_path)
        
        source = st.camera_input("ØµÙˆÙ‘Ø± Ø§Ù„Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ù…Ø¬Ù‡Ø±")
        if source:
            image = Image.open(source).convert("RGB")
            st.image(image, caption="Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©", use_container_width=True)
            
            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø©
            size = (224, 224)
            image = ImageOps.fit(image, size, Image.Resampling.LANCZOS)
            img_array = np.asarray(image).astype(np.float32) / 127.5 - 1
            data = np.expand_dims(img_array, axis=0)
            
            # --- Ø§Ù„ØªÙˆÙ‚Ø¹ Ø§Ù„Ù…Ø¨Ø§Ø´Ø± (ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ù‚Ù†Ø§Ø¹ ØªÙ…Ø§Ù…Ø§Ù‹) ---
            # Ù†Ø³ØªØ®Ø¯Ù… Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø§Ù„Ø·Ø¨Ù‚Ø© Ù…Ø¨Ø§Ø´Ø±Ø© Ø¨Ø¯ÙˆÙ† predict() Ù„ØªØ¬Ù†Ø¨ Ø¥Ø±Ø³Ø§Ù„ mask
            prediction = model(tf.constant(data), training=False)
            if hasattr(prediction, "numpy"):
                prediction = prediction.numpy()
            
            index = np.argmax(prediction)
            confidence = prediction[0][index] * 100
            
            st.balloons()
            st.success(f"Ø§Ù„Ù†ØªÙŠØ¬Ø©: {class_names[index]}")
            st.metric("Ø¯Ù‚Ø© Ø§Ù„ØªØ´Ø®ÙŠØµ", f"{confidence:.2f}%")
            
    except Exception as e:
        st.error(f"Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {e}")
else:
    st.warning("ÙŠØ±Ø¬Ù‰ Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù…Ù„ÙØ§Øª .h5 Ùˆ .txt")
